{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from everything import *\n",
    "\n",
    "with open(\"music.pk\", \"rb\") as f:\n",
    "    music = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying composer by music snippet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First concatentate the arrays for each composer and split into manageable 256 length chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "groups = lambda: itertools.groupby(music, lambda x: x[\"composer\"])\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "block_per_composer = (\n",
    "    (composer, vstack(x[\"piece\"] for x in pieces).tocsr()) for composer, pieces in groups()\n",
    ")\n",
    "\n",
    "chunk_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = itertools.chain([\n",
    "    (i[0], i[1][j : j + chunk_size])\n",
    "    for j in range(0, i[1].shape[0], chunk_size)]\n",
    "    for i in block_per_composer\n",
    ")\n",
    "final = list(itertools.chain(*data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any wrongly sized chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [i for i in final if i[1].shape==(chunk_size,128)]\n",
    "import random \n",
    "random.shuffle(final)\n",
    "y = [i[0] for i in final]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets listen to some music! See if we can guess correctly. Using pygame here to play the music!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'albeniz_suite_espanola_47_02_cataluna_(c)yogore.mid', 'composer': 'Albeniz', 'piece': <7368x128 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 28387 stored elements in COOrdinate format>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bach, J.S': 13512,\n",
       " 'Mozart': 9147,\n",
       " 'Beethoven': 6583,\n",
       " 'Schubert': 6112,\n",
       " 'Haydn, F': 3389,\n",
       " 'Tchaikovsky': 3386,\n",
       " 'Chopin': 3267,\n",
       " 'Scarlatti, D': 3149,\n",
       " 'Brahms': 3071,\n",
       " 'Handel': 3026,\n",
       " 'Alkan': 2774,\n",
       " 'Dvořák': 2367,\n",
       " 'Schumann': 1903,\n",
       " 'Saint-Saëns': 1387,\n",
       " 'Debussy': 1345,\n",
       " 'Byrd': 1260,\n",
       " 'Mahler': 1042,\n",
       " 'Clementi': 983,\n",
       " 'Dandrieu': 979,\n",
       " 'Mendelssohn-B': 963,\n",
       " 'Frescobaldi': 921,\n",
       " 'Fauré': 810,\n",
       " 'Pachelbel, J': 800,\n",
       " 'Albeniz': 786,\n",
       " 'Ravel': 671,\n",
       " 'Buxtehude': 495,\n",
       " 'Rachmaninov': 462,\n",
       " 'Mussorgsky': 442,\n",
       " 'Stravinsky': 408,\n",
       " 'Froberger': 380,\n",
       " 'Telemann': 342,\n",
       " 'Satie': 337,\n",
       " 'Vivaldi': 265,\n",
       " 'Reger': 199,\n",
       " 'Gesualdo da Venosa': 195,\n",
       " 'Bartók': 195,\n",
       " 'Pres (Despres)': 145,\n",
       " 'Scriabin': 125,\n",
       " 'Praetorius': 116,\n",
       " 'Couperin': 4}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=Counter(i[0] for i in final)\n",
    "num_comp = len(x)\n",
    "print(music[0])\n",
    "dict(sorted(((i,j) for i,j in x.items()), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import music as mus\n",
    "import pygame\n",
    "import os\n",
    "def play(piece):\n",
    "    pygame.init()\n",
    "    name = f\"tester.mid\"\n",
    "    write_midi(piece.toarray()*127, name)\n",
    "    pygame.mixer.music.load(name)\n",
    "    pygame.mixer.music.play()\n",
    "    os.remove(name)\n",
    "    \n",
    "def play_snippet(comp):\n",
    "    pygame.init()\n",
    "    name = f\"tester.mid\"\n",
    "    snippet = random.choice([i for i in final if i[0]==comp])[1]\n",
    "    mus.write_midi(snippet.toarray()*127, name)\n",
    "    pygame.mixer.music.load(name)\n",
    "    pygame.mixer.music.play()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_snippet(\"Bach, J.S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    answers = []\n",
    "    for i, (comp, snippet) in enumerate(final[:50]):\n",
    "        name = f\"tester.mid\"\n",
    "        mus.write_midi(snippet.toarray()*127, name)\n",
    "        pygame.mixer.music.load(name)\n",
    "        pygame.mixer.music.play()\n",
    "        inp = input(\"Who was it?\")\n",
    "        if len(inp)>=3 and inp in comp:\n",
    "            print(f\"Correct the composer was {comp}\")\n",
    "            answers.append((comp, True))\n",
    "        else:\n",
    "            print(f\"Incorrect the composer was {comp}\")\n",
    "            answers.append((comp, False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "y= le.fit_transform(y)\n",
    "X = [i[1] for i in final]\n",
    "n=len(y)\n",
    "test_size = n//5\n",
    "X_train, y_train = X[test_size:], y[test_size:]\n",
    "X_test, y_test = X[:test_size], y[:test_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will to need make generator to make sure they are passed as right format but not run out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_batchs(x, y, batch_size ):\n",
    "    xi = iter(x)\n",
    "    yi = iter(y)\n",
    "    while True:\n",
    "        try:\n",
    "            n = (np.array([np.array(next(xi).toarray()) for i in range(batch_size)]),np.array([next(yi) for i in range(batch_size)]))\n",
    "        except StopIteration:\n",
    "                 xi = iter(x)\n",
    "                 yi = iter(y)\n",
    "            \n",
    "        yield n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see the results of a standard nn in classifing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(256, 128)))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(num_comp, activation=tf.nn.softmax))\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit_generator(to_batchs(X_train, y_train, 1024), epochs=3, steps_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(to_batchs(X_test,y_test, 32), steps=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not very spectacular. As we can see below it only has 25% accuracy when our best guess at mozart is 14%! The high accuracy in training also indicateds it is highly overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bach, J.S', 17.38),\n",
       " ('Mozart', 11.77),\n",
       " ('Beethoven', 8.47),\n",
       " ('Schubert', 7.86),\n",
       " ('Haydn, F', 4.36),\n",
       " ('Tchaikovsky', 4.36),\n",
       " ('Chopin', 4.2),\n",
       " ('Scarlatti, D', 4.05),\n",
       " ('Brahms', 3.95),\n",
       " ('Handel', 3.89)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "sorted(((i,(round(100*j/len(y),2))) for i,j in Counter(le.inverse_transform(y)).items()), key=lambda x:x[1], reverse=True)[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets try a convolutional network now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_conv_batchs(x, y, batch_size ):\n",
    "    xi = iter(x)\n",
    "    yi = iter(y)\n",
    "    while True:\n",
    "        try:\n",
    "            xb = np.array([np.array(next(xi).toarray()).reshape(chunk_size,128,1) for i in range(batch_size)])\n",
    "            yb = np.array([next(yi)for i in range(batch_size)])\n",
    "            n = (xb,yb)\n",
    "        except StopIteration:\n",
    "                 xi = iter(x)\n",
    "                 yi = iter(y)\n",
    "            \n",
    "        yield n\n",
    "        \n",
    "#x = to_conv_batchs(X_train, y_train, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D,Dropout\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(32, kernel_size=(4,4), activation=\"relu\", input_shape=(chunk_size, 128,1)))\n",
    "model.add(Conv2D(16, kernel_size=(4,4), activation=\"relu\"))\n",
    "model.add(Conv2D(8, kernel_size=(4,4), activation=\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_comp, activation=\"softmax\"))\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[4,4,32,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training_3/Adam/Variable_10/Assign (defined at C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:402)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_3/Adam/Variable_10, training_3/Adam/zeros_10)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_3/Adam/Variable_10/Assign', defined at:\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3215, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-300-fe1bde1b1159>\", line 1, in <module>\n    model.fit_generator(to_conv_batchs(X_train, y_train, 8), epochs=6, steps_per_epoch=100)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1418, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 40, in fit_generator\n    model._make_train_function()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 509, in _make_train_function\n    loss=self.total_loss)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py\", line 488, in get_updates\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py\", line 488, in <listcomp>\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 704, in zeros\n    return variable(v, dtype=dtype, name=name)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 402, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1481, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4,4,32,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training_3/Adam/Variable_10/Assign (defined at C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:402)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_3/Adam/Variable_10, training_3/Adam/zeros_10)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4,4,32,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_3/Adam/Variable_10/Assign}} = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_3/Adam/Variable_10, training_3/Adam/zeros_10)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-300-fe1bde1b1159>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_conv_batchs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2697\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2698\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2699\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;31m# hack for list_devices() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4,4,32,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training_3/Adam/Variable_10/Assign (defined at C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:402)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_3/Adam/Variable_10, training_3/Adam/zeros_10)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_3/Adam/Variable_10/Assign', defined at:\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3215, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-300-fe1bde1b1159>\", line 1, in <module>\n    model.fit_generator(to_conv_batchs(X_train, y_train, 8), epochs=6, steps_per_epoch=100)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1418, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 40, in fit_generator\n    model._make_train_function()\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 509, in _make_train_function\n    loss=self.total_loss)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py\", line 488, in get_updates\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py\", line 488, in <listcomp>\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 704, in zeros\n    return variable(v, dtype=dtype, name=name)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 402, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1481, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4,4,32,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training_3/Adam/Variable_10/Assign (defined at C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:402)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_3/Adam/Variable_10, training_3/Adam/zeros_10)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(to_conv_batchs(X_train, y_train, 8), epochs=6, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.524674486517906, 0.300859375]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(to_conv_batchs(X_test,y_test, 32), steps=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"conv-classical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jembi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024, 128, 1)\n",
      "PREDICTED  Mozart  ACTUAL  Alkan\n",
      "0.21263775\n",
      "[6.75711734e-03 2.77162697e-02 6.61955997e-02 7.39755225e-04\n",
      " 1.00456811e-01 5.05469218e-02 2.74099963e-04 8.41391593e-05\n",
      " 5.73112406e-02 9.70564224e-03 1.84483797e-04 6.86509360e-04\n",
      " 1.74814742e-02 3.57328802e-02 6.50345720e-03 2.71426106e-04\n",
      " 1.29963199e-04 1.60702431e-04 3.32118524e-03 3.98032889e-02\n",
      " 1.43419229e-03 8.09417758e-03 2.12637752e-01 1.43039366e-03\n",
      " 2.70365359e-04 3.35782417e-04 2.75095081e-04 1.54376845e-03\n",
      " 7.27289007e-04 1.84798019e-03 1.78480726e-02 4.80968243e-04\n",
      " 2.55208388e-02 1.86049476e-01 7.87518267e-03 3.61602579e-04\n",
      " 6.56327838e-03 1.01428695e-01 7.90871622e-04 4.21171135e-04]\n"
     ]
    }
   ],
   "source": [
    "import pypianoroll\n",
    "def write_midi(arr, filename):\n",
    "    pypianoroll.Multitrack(tracks=[pypianoroll.Track(arr)]).write(filename)\n",
    "n = 169\n",
    "piece_s, composer = X_test[n], y_test[n]\n",
    "piece = np.expand_dims(piece_s.toarray(), axis=3)\n",
    "piece = np.expand_dims(piece, axis=0)\n",
    "composer = np.expand_dims(composer, axis=0)\n",
    "print(piece.shape)\n",
    "pred = model.predict(piece)[0]\n",
    "comp_num = np.argmax(pred)\n",
    "print(\"PREDICTED \",le.classes_[comp_num],\" ACTUAL \", le.classes_[composer[0]])\n",
    "play(piece_s)\n",
    "print(max(pred))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 1021, 125, 64)     1088      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1018, 122, 32)     32800     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3974272)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                158970920 \n",
      "=================================================================\n",
      "Total params: 159,004,808\n",
      "Trainable params: 159,004,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_dups(mus):\n",
    "    encoutered = set(pickle.dumps(i[\"piece\"]) for i in mus)            \n",
    "    return len(mus)-len(encoutered)\n",
    "num_dups(music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
